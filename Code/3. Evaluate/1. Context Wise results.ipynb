{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Wise MM results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_preds = Path(\"../../Preds/MotionSound/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context and activities\n",
    "contexts = {\n",
    "    'Bathroom': ['Brushing_hair', 'Hair_dryer_in_use', 'Shaver_in_use', 'Toilet_flushing', 'Toothbrushing', 'Washing_hands'],\n",
    "    'Kitchen': ['Blender_in_use', 'Chopping', 'Grating', 'Microwave', 'Pouring_pitcher', 'Twisting_jar', 'Washing_Utensils', 'Wiping_with_rag'],\n",
    "    'Misc': ['Alarm_clock', 'Clapping', 'Coughing', 'Drinking', 'Knocking', 'Laughing', 'Scratching'],\n",
    "    'Workshop': ['Drill in use', 'Hammering', 'Sanding', 'Screwing', 'Vacuum in use']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sr_metrics = []\n",
    "for sub_sr_path in path_to_preds.iterdir():\n",
    "    if sub_sr_path.is_file():\n",
    "        continue\n",
    "    sub_sr = sub_sr_path.name\n",
    "    \n",
    "    bas = defaultdict(list)\n",
    "    for fpath in (sub_sr_path).iterdir():\n",
    "        pred_df = pd.read_csv(fpath)\n",
    "        pred_df[[\"PID\", \"Context\", \"Activity\", \"TrialNo\"]] = pred_df[\"file_name\"].str.split(\"---\").to_list()\n",
    "        \n",
    "        preds = defaultdict(list)\n",
    "        for name, group in pred_df.groupby([\"file_name\"]):\n",
    "            probs = group.drop(columns=[\"file_name\", \"y_pred\", \"y_true\", \"PID\", \"Context\", \"Activity\", \"TrialNo\"])\n",
    "\n",
    "            group_context = group[\"Context\"].unique()[0]\n",
    "            group_activity = group[\"y_true\"].unique()[0]\n",
    "            if group_context == \"Other\":\n",
    "                continue\n",
    "            if group_context == \"All\":\n",
    "                continue\n",
    "\n",
    "            filtered_probs = probs[contexts[group_context]]\n",
    "            summed_probs = filtered_probs.sum(axis=0)\n",
    "            y_pred = summed_probs.idxmax()\n",
    "\n",
    "            preds[group_context].append([group_activity, y_pred])\n",
    "            \n",
    "        for context in preds.keys():\n",
    "            preds_arr = np.array(preds[context])\n",
    "            bas[context].append(balanced_accuracy_score(preds_arr[:, 0], preds_arr[:, 1]))\n",
    "    \n",
    "    for context in bas.keys():\n",
    "        context_mean = np.mean(bas[context])\n",
    "        context_std = np.std(bas[context])\n",
    "        \n",
    "        sub_sr_metrics.append([sub_sr, context_mean, context_std, context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(sub_sr_metrics, columns=[\"sub_sr\", \"mean\", \"std\", \"context\"])\n",
    "results[\"sub_sr\"] = results[\"sub_sr\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name, group in results.groupby([\"context\"]):\n",
    "    data = group.sort_values(by=[\"sub_sr\"], ascending=False)\n",
    "    display(data.drop(columns=[\"context\"]).set_index(\"sub_sr\"))\n",
    "    \n",
    "    plt.plot(data[\"sub_sr\"], data[\"mean\"])\n",
    "    plt.ylim([0.4, 1.0])\n",
    "    plt.xscale(\"log\")\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaged accross contexts\n",
    "results.groupby(\"sub_sr\").mean().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Wise Sound Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_preds = Path(\"../../Preds/Sound/\")\n",
    "sub_sr_metrics = []\n",
    "for sub_sr_path in path_to_preds.iterdir():\n",
    "    if sub_sr_path.is_file():\n",
    "        continue\n",
    "    sub_sr = sub_sr_path.name\n",
    "    \n",
    "    bas = defaultdict(list)\n",
    "    for fpath in (sub_sr_path).iterdir():\n",
    "        pred_df = pd.read_csv(fpath)\n",
    "        pred_df[[\"PID\", \"Context\", \"Activity\", \"TrialNo\"]] = pred_df[\"file_name\"].str.split(\"---\").to_list()\n",
    "        \n",
    "        preds = defaultdict(list)\n",
    "        for name, group in pred_df.groupby([\"file_name\"]):\n",
    "            probs = group.drop(columns=[\"file_name\", \"y_pred\", \"y_true\", \"PID\", \"Context\", \"Activity\", \"TrialNo\"])\n",
    "\n",
    "            group_context = group[\"Context\"].unique()[0]\n",
    "            group_activity = group[\"y_true\"].unique()[0]\n",
    "            if group_context == \"Other\":\n",
    "                continue\n",
    "            if group_context == \"All\":\n",
    "                continue\n",
    "\n",
    "            filtered_probs = probs[contexts[group_context]]\n",
    "            summed_probs = filtered_probs.sum(axis=0)\n",
    "            y_pred = summed_probs.idxmax()\n",
    "\n",
    "            preds[group_context].append([group_activity, y_pred])\n",
    "            \n",
    "        for context in preds.keys():\n",
    "            preds_arr = np.array(preds[context])\n",
    "            bas[context].append(balanced_accuracy_score(preds_arr[:, 0], preds_arr[:, 1]))\n",
    "    \n",
    "    for context in bas.keys():\n",
    "        context_mean = np.mean(bas[context])\n",
    "        context_std = np.std(bas[context])\n",
    "        \n",
    "        sub_sr_metrics.append([sub_sr, context_mean, context_std, context])\n",
    "        \n",
    "results = pd.DataFrame(sub_sr_metrics, columns=[\"sub_sr\", \"mean\", \"std\", \"context\"])\n",
    "results[\"sub_sr\"] = results[\"sub_sr\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name, group in results.groupby([\"context\"]):\n",
    "    data = group.sort_values(by=[\"sub_sr\"], ascending=False)\n",
    "    display(data.drop(columns=[\"context\"]).set_index(\"sub_sr\"))\n",
    "    \n",
    "    plt.plot(data[\"sub_sr\"], data[\"mean\"])\n",
    "    plt.ylim([0.4, 1.0])\n",
    "    plt.xscale(\"log\")\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby(\"sub_sr\").mean().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_preds = Path(\"../../Preds/Motion/\")\n",
    "\n",
    "bas = defaultdict(list)\n",
    "for fpath in (path_to_preds).iterdir():\n",
    "    pred_df = pd.read_csv(fpath)\n",
    "    pred_df[[\"PID\", \"Context\", \"Activity\", \"TrialNo\"]] = pred_df[\"file_name\"].str.split(\"---\").to_list()\n",
    "\n",
    "    preds = defaultdict(list)\n",
    "    for name, group in pred_df.groupby([\"file_name\"]):\n",
    "        probs = group.drop(columns=[\"file_name\", \"y_pred\", \"y_true\", \"PID\", \"Context\", \"Activity\", \"TrialNo\"])\n",
    "\n",
    "        group_context = group[\"Context\"].unique()[0]\n",
    "        group_activity = group[\"y_true\"].unique()[0]\n",
    "        if group_context == \"Other\":\n",
    "            continue\n",
    "        if group_context == \"All\":\n",
    "            continue\n",
    "\n",
    "        filtered_probs = probs[contexts[group_context]]\n",
    "        summed_probs = filtered_probs.sum(axis=0)\n",
    "        y_pred = summed_probs.idxmax()\n",
    "\n",
    "        preds[group_context].append([group_activity, y_pred])\n",
    "\n",
    "    for context in preds.keys():\n",
    "        preds_arr = np.array(preds[context])\n",
    "        bas[context].append(balanced_accuracy_score(preds_arr[:, 0], preds_arr[:, 1]))\n",
    "\n",
    "results = []\n",
    "for context in bas.keys():\n",
    "    context_mean = np.mean(bas[context])\n",
    "    context_std = np.std(bas[context])\n",
    "\n",
    "    results.append([context, context_mean, context_std])\n",
    "    # sub_sr_metrics.append([sub_sr, context_mean, context_std, context])\n",
    "results = pd.DataFrame(results, columns=[\"context\", \"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
